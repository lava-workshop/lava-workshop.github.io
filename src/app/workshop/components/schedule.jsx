const Schedule = () => {
    return <div className="text-justify">
        <span className="font-bold text-[1.3em]">Morning Session</span>
        <ul className="list-disc list-inside space-y-2 mt-2 ml-4">
            <li> <span className="font-bold">--:--</span> - Opening Remark</li>
            <li><span className="font-bold">--:--</span> - Keynote Talk: Dr. Md. Mamunur Rashid (The King Abdulaziz Center for World Culture - Ithra) Cross-Modal Trust: Evaluating LVLMs for Safeguarding Health Information</li>
            <li><span className="font-bold">--:--</span> - Janak Kapuriya: Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning</li>
            <li><span className="font-bold">--:--</span> - Jiadong Yan (online): Few-shot Anomaly Detection based on Long Short Text Interactive Contrastive Learning</li>
            <li><span className="font-bold">--:--</span> - Tun-Yuan Chang: Harvesting Temporal Correlation in Large Vision-Language Models: Using Pose Estimation as a Case Study</li>
            <li><span className="font-bold">--:--</span> - Nam Nguyen Xuan (online): StructCon-ST: Connectivity-Aware Spatio-Temporal Fine-Grained Image Analysis</li>
            <li><span className="font-bold">--:--</span> - Jun Wan (pre-recorded video): Hierarchical Temporal Views for Policy Optimization in Multimodal Video Reasoning</li>
        </ul>

        <span className="font-bold text-[1.3em]">Afternoon Session</span>
        <ul className="list-disc list-inside space-y-2 mt-2 ml-4">
            <li><span className="font-bold">--:--</span> - Keynote Talk: Dr. Seitaro Shinagawa (SB Intuitions, online) Sarashina2-Vision: Toward Vision -- Language Models for Understanding Japanese Figures and Conceptual/Explanatory Diagrams</li>
            <li><span className="font-bold">--:--</span> - Daichi Sato: LAVA Grand Challenge Introduction</li>
            <li><span className="font-bold">--:--</span> - SYSUpporter team: HEAR: A Holistic Extraction and Agentic Reasoning Framework for Document Understanding</li>
            <li><span className="font-bold">--:--</span> - Woof team: AdaDocVQA: Adaptive Framework for Long Document Visual Question Answering in Low-Resource Settings</li>
            <li><span className="font-bold">--:--</span> - nsbsk team: Hierarchical Vision-Language Reasoning for Multimodal Multiple-Choice Question Answering</li>
            <li><span className="font-bold">--:--</span> - char team: wo-Stage Approach Using a Pretrained Language Model for Question Answering on Japanese Document Images</li>
        </ul>
    </div>
}
export default Schedule;
